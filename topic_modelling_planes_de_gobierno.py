# -*- coding: utf-8 -*-
"""topic_modelling_planes_de_gobierno.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10wNKSx16loiwQBEXfQT5PhIGUTC8NGtl
"""

#montaje de drive
from google.colab import drive
drive.mount('/content/drive')

!python -m spacy download es_core_news_sm

import re
import spacy
import fitz
from sklearn.feature_extraction.text import CountVectorizer

"""Cargamos el PDF"""

ruta_pdf = '/content/drive/MyDrive/AnaÌlisis de Textos y Redes Sociales/trabajo_final/trabajo_final_planes_de_gobierno/Somos-Peru-Plan-de-Gobierno-LP-derecho.pdf'

def pdf_to_text(path_pdf):
  doc = fitz.open(path_pdf)
  text = ""
  for page in doc:
    text += page.get_text()
  return text

text = pdf_to_text(ruta_pdf)

"""Preprocesando el texto"""

nlp = spacy.load("es_core_news_sm")
nlp.max_length = 1500000 # Increase max_length to handle larger texts
def preprocess(text):
  text = text.lower()
  text = re.sub(r"\d+", "", text)
  text = re.sub(r"[^\w\s]", "", text)

  doc = nlp(text)
  tokens = [
      token.lemma_
      for token in doc
      if not token.is_stop and len(token) > 2
  ]
  return " ".join(tokens)

clean_text = preprocess(text)

"""Detectando n-gramas"""

vectorizer = CountVectorizer(
    ngram_range=(1, 3),
    max_df = 1.0, # Changed max_df to 1.0 to handle a single document correctly
    min_df = 1
)

X = vectorizer.fit_transform([clean_text])
terms = vectorizer.get_feature_names_out()

frequencies = X.toarray()[0]

top_terms = sorted(
    zip(terms, frequencies),
    key = lambda x: x[1],
    reverse=True
)[:100]

for term, freq in top_terms:
  print(term, freq)